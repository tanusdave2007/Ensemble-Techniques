{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "THEORITICAL QUESTIONS AND ANSWERS"
      ],
      "metadata": {
        "id": "JJTcVmku_uW1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1. Can we use Bagging for regression problems?\n",
        "\n",
        "Answer 1. Yes, Bagging (Bootstrap Aggregating) can be effectively used for regression problems. It is known as a Bagging Regressor. It involves training multiple independent base regressors on different bootstrap samples of the training data. The final prediction is then obtained by averaging the predictions from all the individual regressors. This process helps to reduce the variance of the overall model."
      ],
      "metadata": {
        "id": "gIvADhO8_xY_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2. What is the difference between multiple model training and single model training\n",
        "\n",
        "Answer 2. Single model training fits one model (e.g., a single Decision Tree) to the entire dataset. Multiple model training, or ensemble learning, trains several base models (e.g., multiple trees) on the data. The goal of single training is to find the best fit from one hypothesis space, while multiple training combines the predictions of many models to achieve a more robust and generally better final result, typically by reducing variance or bias."
      ],
      "metadata": {
        "id": "F29u-qK1_xWk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3. Explain the concept of feature randomness in Random Forest\n",
        "\n",
        "Answer 3. Feature randomness in Random Forest means that at each node split during the construction of a tree, the algorithm considers only a random subset of the total features. It does not look at all available features. This process, controlled by a hyperparameter like $max\\_features$, ensures the individual trees are diverse (decorrelated) and prevents strong features from dominating all trees, which is key to reducing variance and preventing overfitting."
      ],
      "metadata": {
        "id": "IZpRhbnM_xUF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4. What is OOB (Out-of-Bag) Score\n",
        "\n",
        "Answer 4. The Out-of-Bag (OOB) score is an internal validation method for ensemble models like Random Forest that use bootstrap sampling. For each base model, the OOB samples are the data points that were not included in its bootstrap training set. The OOB score is calculated by using each data point's OOB models to predict it, and then aggregating these predictions to estimate the model's generalization accuracy, eliminating the need for a separate cross-validation set."
      ],
      "metadata": {
        "id": "e9aHkekQ_xRi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5. How can you measure the importance of features in a Random Forest model\n",
        "\n",
        "Answer 5. Feature importance is typically measured by calculating the mean decrease in impurity (MDI) or Gini importance. This metric quantifies the average reduction in the objective function (like Gini impurity or MSE) contributed by that feature across all the trees in the forest. A higher mean decrease in impurity indicates a more important feature. Alternatively, the permutation importance method measures the decrease in the model's score when a feature's values are randomly shuffled."
      ],
      "metadata": {
        "id": "bN8KT72E_xOd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6. Explain the working principle of a Bagging Classifier\n",
        "\n",
        "Answer 6. A Bagging Classifier works by creating $N$ subsets of the original training data using bootstrap sampling (sampling with replacement). It then trains $N$ independent base classifiers (e.g., Decision Trees) on each of these subsets. For a new data point, each base classifier makes a prediction, and the final prediction is determined by the majority vote among all the classifiers."
      ],
      "metadata": {
        "id": "RBvgWuKZ_xLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7. How do you evaluate a Bagging Classifierâ€™s performance\n",
        "\n",
        "Answer 7. A Bagging Classifier's performance can be evaluated using standard metrics like accuracy, precision, recall, and F1-score on a hold-out test set. Alternatively, the Out-of-Bag (OOB) score provides an estimate of the model's generalization error without needing cross-validation or a separate validation set, by using the samples not seen by each base estimator for validation."
      ],
      "metadata": {
        "id": "aT9xoVw__xJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8. How does a Bagging Regressor work\n",
        "\n",
        "Answer 8. A Bagging Regressor follows the same principle as the Bagging Classifier but is adapted for continuous output prediction. It trains multiple base regressors on bootstrap samples of the data. However, instead of using a majority vote for the final output, it computes the average of the predictions made by all the individual base regressors. This averaging process reduces the variance of the overall model's prediction."
      ],
      "metadata": {
        "id": "yKCV_aArAb1Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9. What is the main advantage of ensemble techniques\n",
        "\n",
        "Answer 9. The main advantage of ensemble techniques is their ability to significantly improve predictive accuracy and stability over a single base model. They achieve this by combining predictions from multiple diverse models. Specifically, Bagging reduces variance (overfitting), while Boosting primarily reduces bias, leading to more robust and generalized models."
      ],
      "metadata": {
        "id": "1v8G53uzAbya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10. What is the main challenge of ensemble methods\n",
        "\n",
        "Answer 10. The main challenge of ensemble methods is increased computational cost and complexity. Training multiple base models is more time-consuming and resource-intensive than training a single model. Additionally, the final ensemble model is less interpretable, making it harder to explain why a specific prediction was made compared to simpler models like a single Decision Tree or Linear Regression."
      ],
      "metadata": {
        "id": "BuDIH-hEAbvx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 11. Explain the key idea behind ensemble techniques\n",
        "\n",
        "Answer 11. The key idea behind ensemble techniques is that a group of \"weak learners\" or base models, when strategically combined, can create a \"strong learner\" that is much better than any single component model. By inducing diversity among the base models and combining their results, the ensemble aims to average out individual model errors and noise, resulting in a more accurate and stable prediction."
      ],
      "metadata": {
        "id": "0N8XdOQhAbsh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 12. What is a Random Forest Classifier\n",
        "\n",
        "Answer 12. A Random Forest Classifier is an ensemble learning method specifically designed for classification tasks, built upon the Bagging technique. It constructs a large number of independent Decision Trees. Crucially, it introduces two sources of randomness: bootstrap sampling of data and feature randomness at each split. The final prediction is made by the majority vote of the individual tree predictions."
      ],
      "metadata": {
        "id": "xk-Wt_XwAbph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 13. What are the main types of ensemble techniques\n",
        "\n",
        "Answer 13. The main types of ensemble techniques are generally categorized into three groups: Bagging (Bootstrap Aggregating, e.g., Random Forest), which focuses on reducing variance and parallelism; Boosting (e.g., AdaBoost, Gradient Boosting), which focuses on sequentially correcting model errors to reduce bias; and Stacking (Stacked Generalization), which combines the predictions of multiple diverse models using a meta-learner."
      ],
      "metadata": {
        "id": "8qkVJBSVA3NC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 14. What is ensemble learning in machine learning\n",
        "\n",
        "Answer 14. Ensemble learning is a general machine learning paradigm where multiple models (often called base estimators or weak learners) are trained to solve the same problem. Instead of relying on a single model, the goal is to combine the predictions of these individual models to obtain a final prediction that is generally more accurate and robust than the individual predictions."
      ],
      "metadata": {
        "id": "Cdp5va1HA3KY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 15. When should we avoid using ensemble methods\n",
        "\n",
        "Answer 15. Ensemble methods should be avoided when model interpretability is a critical requirement, as their complexity makes them hard to explain. They may also be avoided on small datasets where the benefits of diversity are minimal, or when computational resources (time/memory) are severely limited, as training and maintaining multiple models is resource-intensive."
      ],
      "metadata": {
        "id": "KCqxTmhUA3Bq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 16. How does Bagging help in reducing overfitting\n",
        "\n",
        "Answer 16. Bagging reduces overfitting by primarily targeting variance. By training base models on different bootstrap subsets, the models become somewhat independent and diverse. When their predictions are aggregated (via averaging or majority vote), the high variance (sensitivity to the training data) of individual models is smoothed out, leading to a more stable and generalized overall prediction."
      ],
      "metadata": {
        "id": "UfJsCnWsA2-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 17. Why is Random Forest better than a single Decision Tree\n",
        "\n",
        "Answer 17. A Random Forest is generally better than a single Decision Tree because the single tree is prone to overfitting (high variance) the training data by growing to maximum depth. Random Forest averages the predictions of many different, decorrelated trees, which effectively reduces the variance of the model without significantly increasing the bias. This results in superior generalization performance on unseen data."
      ],
      "metadata": {
        "id": "e-4Lrd_fA275"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 18. What is the role of bootstrap sampling in Bagging\n",
        "\n",
        "Answer 18. Bootstrap sampling is the process of drawing random samples with replacement from the original training dataset to create multiple training subsets. Its role in Bagging is to create diversity among the base models. Since each subset is slightly different, the base models trained on them will have different error patterns, which is essential for the ensemble to successfully reduce variance when the final predictions are combined."
      ],
      "metadata": {
        "id": "0a1P3POXA2yw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 19. What are some real-world applications of ensemble techniques\n",
        "\n",
        "Answer 19. Ensemble techniques are widely used in many fields. Key applications include predictive modeling in finance (e.g., credit scoring, fraud detection), image classification and object recognition (often using variations of Boosting/Stacking on deep networks), medical diagnosis for improved accuracy, and in competitive machine learning like Kaggle where they are often the basis for winning solutions."
      ],
      "metadata": {
        "id": "_ORoah-0A2vi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 20. What is the difference between Bagging and Boosting\n",
        "\n",
        "Answer 20. Bagging (e.g., Random Forest) trains models in parallel on independent bootstrap samples, aiming to reduce variance and prevent overfitting. Boosting (e.g., AdaBoost) trains models sequentially, where each subsequent model tries to correct the errors of the previous ones, aiming to reduce bias. Bagging combines results via average/vote, while Boosting combines results using a weighted average."
      ],
      "metadata": {
        "id": "HD2T0ivNA2sw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PRACTICAL QUESTIONS AND ANSWERS"
      ],
      "metadata": {
        "id": "DvYmbY-dBYaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#21. Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy"
      ],
      "metadata": {
        "id": "13R2xd1ECWvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Generate a synthetic dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=0, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define the base estimator and the Bagging Classifier\n",
        "base_estimator = DecisionTreeClassifier(random_state=42)\n",
        "bag_clf = BaggingClassifier(\n",
        "    estimator=base_estimator,\n",
        "    n_estimators=100,  # Number of base estimators\n",
        "    max_samples=1.0,   # Sample 100% of the training set\n",
        "    bootstrap=True,    # Use bootstrap sampling\n",
        "    n_jobs=-1,         # Use all processors\n",
        "    random_state=42)\n",
        "\n",
        "# Train the model\n",
        "bag_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = bag_clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Bagging Classifier Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKiu1mJbCNpz",
        "outputId": "b91a2d7a-566c-477a-917f-d480a862ee2f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Accuracy: 0.9200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#22. Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE)"
      ],
      "metadata": {
        "id": "QkjACr7LCSn-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Generate a synthetic dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define the base estimator and the Bagging Regressor\n",
        "base_estimator = DecisionTreeRegressor(random_state=42)\n",
        "bag_reg = BaggingRegressor(\n",
        "    estimator=base_estimator,\n",
        "    n_estimators=100,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "bag_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = bag_reg.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(f\"Bagging Regressor Mean Squared Error (MSE): {mse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsuIMRfOB0cb",
        "outputId": "0278706f-10ae-459a-d21a-a6fca450e23b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Regressor Mean Squared Error (MSE): 211.5435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#23. Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores"
      ],
      "metadata": {
        "id": "k7tsHhFeCqAW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "feature_names = data.feature_names\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "importances = rf_clf.feature_importances_\n",
        "\n",
        "# Create a list of feature names and their importance scores\n",
        "feature_importances = list(zip(feature_names, importances))\n",
        "\n",
        "# Sort the features by importance score\n",
        "feature_importances.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"Feature Importance Scores:\")\n",
        "for name, importance in feature_importances:\n",
        "    print(f\"{name}: {importance:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrlVFWbKCrkA",
        "outputId": "de9160a6-4475-461b-893f-d3eff2d07fee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance Scores:\n",
            "mean concave points: 0.1419\n",
            "worst concave points: 0.1271\n",
            "worst area: 0.1182\n",
            "mean concavity: 0.0806\n",
            "worst radius: 0.0780\n",
            "worst perimeter: 0.0743\n",
            "mean perimeter: 0.0601\n",
            "mean area: 0.0538\n",
            "worst concavity: 0.0411\n",
            "mean radius: 0.0323\n",
            "area error: 0.0295\n",
            "worst texture: 0.0188\n",
            "worst compactness: 0.0175\n",
            "radius error: 0.0164\n",
            "worst symmetry: 0.0129\n",
            "perimeter error: 0.0118\n",
            "worst smoothness: 0.0118\n",
            "mean texture: 0.0111\n",
            "mean compactness: 0.0092\n",
            "fractal dimension error: 0.0071\n",
            "worst fractal dimension: 0.0069\n",
            "mean smoothness: 0.0062\n",
            "smoothness error: 0.0059\n",
            "concavity error: 0.0058\n",
            "compactness error: 0.0046\n",
            "symmetry error: 0.0040\n",
            "concave points error: 0.0034\n",
            "mean symmetry: 0.0033\n",
            "texture error: 0.0032\n",
            "mean fractal dimension: 0.0031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#24. Train a Random Forest Regressor and compare its performance with a single Decision Tree"
      ],
      "metadata": {
        "id": "neJxSjaeCu51"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Generate a synthetic dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 1. Train Random Forest Regressor\n",
        "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_reg.fit(X_train, y_train)\n",
        "y_pred_rf = rf_reg.predict(X_test)\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "\n",
        "# 2. Train Single Decision Tree Regressor\n",
        "tree_reg = DecisionTreeRegressor(random_state=42)\n",
        "tree_reg.fit(X_train, y_train)\n",
        "y_pred_tree = tree_reg.predict(X_test)\n",
        "mse_tree = mean_squared_error(y_test, y_pred_tree)\n",
        "\n",
        "print(f\"Random Forest Regressor MSE: {mse_rf:.4f}\")\n",
        "print(f\"Single Decision Tree Regressor MSE: {mse_tree:.4f}\")\n",
        "print(\"\\nComparison: Lower MSE is better, suggesting the Random Forest performs better due to variance reduction.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_FuNuWTCx_q",
        "outputId": "030b5755-e0ef-4237-f93c-f1aed232e4e4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor MSE: 209.3406\n",
            "Single Decision Tree Regressor MSE: 599.9199\n",
            "\n",
            "Comparison: Lower MSE is better, suggesting the Random Forest performs better due to variance reduction.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#25. Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier"
      ],
      "metadata": {
        "id": "wexQNgZfC3Ek"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest with oob_score=True\n",
        "rf_clf_oob = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    oob_score=True,  # Enable OOB calculation\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_clf_oob.fit(X_train, y_train)\n",
        "\n",
        "# Retrieve the OOB score\n",
        "oob_score = rf_clf_oob.oob_score_\n",
        "\n",
        "print(f\"Random Forest Out-of-Bag (OOB) Score: {oob_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odDYpQ7AC4tp",
        "outputId": "d037a092-4ded-46b3-ebcc-e89f9cc13f47"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Out-of-Bag (OOB) Score: 0.9548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#26. Train a Bagging Classifier using SVM as a base estimator and print accuracy"
      ],
      "metadata": {
        "id": "mTX0wSM7C6Q2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC # Import SVC\n",
        "\n",
        "# Generate a synthetic dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=0, random_state=42)\n",
        "\n",
        "# Scaling is crucial for SVM\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define the base estimator (SVC) and the Bagging Classifier\n",
        "base_estimator = SVC(kernel='linear', random_state=42) # Corrected instantiation\n",
        "bag_svm = BaggingClassifier(\n",
        "    estimator=base_estimator,\n",
        "    n_estimators=10, # Fewer estimators for SVC due to higher computation cost\n",
        "    max_samples=0.8,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "bag_svm.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = bag_svm.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Bagging Classifier (SVC Base) Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPr8AIHEC7bY",
        "outputId": "0a325d06-717f-4916-a9ca-7b1ae4f98f8b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier (SVC Base) Accuracy: 0.7867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#27. Train a Random Forest Classifier with different numbers of trees and compare accuracy"
      ],
      "metadata": {
        "id": "I3SqGe6lC-lH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "n_estimators_list = [10, 50, 200]\n",
        "results = {}\n",
        "\n",
        "print(\"Accuracy Comparison for Different n_estimators:\")\n",
        "for n in n_estimators_list:\n",
        "    rf_clf = RandomForestClassifier(n_estimators=n, random_state=42, n_jobs=-1)\n",
        "    rf_clf.fit(X_train, y_train)\n",
        "    y_pred = rf_clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results[n] = accuracy\n",
        "    print(f\"n_estimators={n}: Accuracy = {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MaDv1CbDN4c",
        "outputId": "5f24dd8d-a1db-45ae-c63d-d0c409eb536a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Comparison for Different n_estimators:\n",
            "n_estimators=10: Accuracy = 0.9649\n",
            "n_estimators=50: Accuracy = 0.9708\n",
            "n_estimators=200: Accuracy = 0.9708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#28. Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score\""
      ],
      "metadata": {
        "id": "cI5pqLWpDPnR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Generate a synthetic dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=0, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define the base estimator (Logistic Regression) and the Bagging Classifier\n",
        "base_estimator = LogisticRegression(solver='liblinear', random_state=42)\n",
        "bag_lr = BaggingClassifier(\n",
        "    estimator=base_estimator,\n",
        "    n_estimators=100,\n",
        "    max_samples=0.8,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "bag_lr.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities (needed for AUC)\n",
        "y_proba = bag_lr.predict_proba(X_test)[:, 1]\n",
        "auc_score = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "print(f\"Bagging Classifier (Logistic Regression Base) AUC Score: {auc_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-0YASHBDkjG",
        "outputId": "1095f42d-29ce-4bc0-a657-366576523599"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier (Logistic Regression Base) AUC Score: 0.8413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#29. Train a Random Forest Regressor and analyze feature importance scores"
      ],
      "metadata": {
        "id": "CM0C775qDpxv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Generate a synthetic dataset with custom feature names\n",
        "X, y = make_regression(n_samples=1000, n_features=8, n_informative=5, random_state=42)\n",
        "feature_names = [f'Feature_{i+1}' for i in range(X.shape[1])]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train the Random Forest Regressor\n",
        "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_reg.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "importances = rf_reg.feature_importances_\n",
        "\n",
        "# Combine names and scores into a DataFrame for analysis\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importances\n",
        "})\n",
        "\n",
        "# Sort and display\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"Random Forest Regressor Feature Importance Analysis:\")\n",
        "print(feature_importance_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuPeqdShDr7n",
        "outputId": "13873a00-8455-4798-83f6-39adfcf93b99"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor Feature Importance Analysis:\n",
            "     Feature  Importance\n",
            "3  Feature_4    0.560083\n",
            "4  Feature_5    0.215373\n",
            "2  Feature_3    0.122355\n",
            "1  Feature_2    0.066225\n",
            "6  Feature_7    0.010332\n",
            "5  Feature_6    0.008834\n",
            "0  Feature_1    0.008657\n",
            "7  Feature_8    0.008141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#30. Train an ensemble model using both Bagging and Random Forest and compare accuracy"
      ],
      "metadata": {
        "id": "p3ZzsxfkDuGO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 1. Train Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "y_pred_rf = rf_clf.predict(X_test)\n",
        "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
        "\n",
        "# 2. Train Bagging Classifier (using simple Decision Trees)\n",
        "base_estimator = DecisionTreeClassifier(random_state=42)\n",
        "bag_clf = BaggingClassifier(\n",
        "    estimator=base_estimator,\n",
        "    n_estimators=100,\n",
        "    max_features=X_train.shape[1], # No feature randomness\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "bag_clf.fit(X_train, y_train)\n",
        "y_pred_bag = bag_clf.predict(X_test)\n",
        "acc_bag = accuracy_score(y_test, y_pred_bag)\n",
        "\n",
        "print(f\"Random Forest Classifier Accuracy: {acc_rf:.4f}\")\n",
        "print(f\"Bagging Classifier Accuracy: {acc_bag:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YumM9QbKDwCb",
        "outputId": "a9ffc14d-de85-49f5-b401-5e947490bc64"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier Accuracy: 0.9708\n",
            "Bagging Classifier Accuracy: 0.9591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#31. Train a Random Forest Classifier and tune hyperparameters using GridSearchCV"
      ],
      "metadata": {
        "id": "iHksxVnYD27x"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define the model and the parameter grid\n",
        "rf_clf = RandomForestClassifier(random_state=42)\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [5, 10, None],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "# Setup GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf_clf,\n",
        "    param_grid=param_grid,\n",
        "    cv=3,  # 3-fold cross-validation\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Perform the search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get best parameters and score\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "# Evaluate on test set using the best estimator\n",
        "best_rf = grid_search.best_estimator_\n",
        "y_pred = best_rf.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "print(f\"Cross-Validation Accuracy: {best_score:.4f}\")\n",
        "print(f\"Test Set Accuracy with Best Model: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9bkEXVRD4dX",
        "outputId": "4bfa7007-c395-4982-d56e-598fd762319e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 50}\n",
            "Cross-Validation Accuracy: 0.9623\n",
            "Test Set Accuracy with Best Model: 0.9708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#32. Train a Bagging Regressor with different numbers of base estimators and compare performance"
      ],
      "metadata": {
        "id": "-plB-tRLD-UF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Generate a synthetic dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "base_estimator = DecisionTreeRegressor(random_state=42)\n",
        "n_estimators_list = [5, 50, 300]\n",
        "results = {}\n",
        "\n",
        "print(\"MSE Comparison for Different n_estimators:\")\n",
        "for n in n_estimators_list:\n",
        "    bag_reg = BaggingRegressor(\n",
        "        estimator=base_estimator,\n",
        "        n_estimators=n,\n",
        "        n_jobs=-1,\n",
        "        random_state=42\n",
        "    )\n",
        "    bag_reg.fit(X_train, y_train)\n",
        "    y_pred = bag_reg.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    results[n] = mse\n",
        "    print(f\"n_estimators={n}: MSE = {mse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUQmOWyhEAKO",
        "outputId": "7d76b015-06df-4e80-9707-28c92995ea06"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Comparison for Different n_estimators:\n",
            "n_estimators=5: MSE = 301.4608\n",
            "n_estimators=50: MSE = 218.6192\n",
            "n_estimators=300: MSE = 206.7753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#33. Train a Random Forest Classifier and analyze misclassified samples"
      ],
      "metadata": {
        "id": "OXthxyxsEB8G"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and identify misclassified samples\n",
        "y_pred = rf_clf.predict(X_test)\n",
        "misclassified_indices = np.where(y_test != y_pred)[0]\n",
        "\n",
        "print(f\"Total misclassified samples: {len(misclassified_indices)}\")\n",
        "print(\"\\nFirst 5 Misclassified Sample Indices and their details:\")\n",
        "for i in misclassified_indices[:5]:\n",
        "    # Use the index 'i' relative to the X_test array\n",
        "    sample_features = X_test[i]\n",
        "    true_label = y_test[i]\n",
        "    predicted_label = y_pred[i]\n",
        "    print(f\"Index in X_test: {i}, True Label: {data.target_names[true_label]}, Predicted Label: {data.target_names[predicted_label]}\")\n",
        "    # print(f\"  Features: {sample_features[:5]}...\") # print first 5 features for brevity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ8cJJHDED22",
        "outputId": "5f200737-1750-4082-87fd-c30821aca8f9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total misclassified samples: 5\n",
            "\n",
            "First 5 Misclassified Sample Indices and their details:\n",
            "Index in X_test: 8, True Label: benign, Predicted Label: malignant\n",
            "Index in X_test: 20, True Label: malignant, Predicted Label: benign\n",
            "Index in X_test: 77, True Label: malignant, Predicted Label: benign\n",
            "Index in X_test: 82, True Label: malignant, Predicted Label: benign\n",
            "Index in X_test: 164, True Label: malignant, Predicted Label: benign\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#34. Train a Bagging Classifier and compare its performance with a single Decision tree Classifier"
      ],
      "metadata": {
        "id": "D9qBGgesEFuC"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 1. Train Single Decision Tree Classifier\n",
        "tree_clf = DecisionTreeClassifier(random_state=42)\n",
        "tree_clf.fit(X_train, y_train)\n",
        "y_pred_tree = tree_clf.predict(X_test)\n",
        "acc_tree = accuracy_score(y_test, y_pred_tree)\n",
        "\n",
        "# 2. Train Bagging Classifier\n",
        "base_estimator = DecisionTreeClassifier(random_state=42)\n",
        "bag_clf = BaggingClassifier(\n",
        "    estimator=base_estimator,\n",
        "    n_estimators=100,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "bag_clf.fit(X_train, y_train)\n",
        "y_pred_bag = bag_clf.predict(X_test)\n",
        "acc_bag = accuracy_score(y_test, y_pred_bag)\n",
        "\n",
        "print(f\"Single Decision Tree Classifier Accuracy: {acc_tree:.4f}\")\n",
        "print(f\"Bagging Classifier Accuracy: {acc_bag:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3gQk1DuEHWr",
        "outputId": "3393c000-7735-4f52-e1ed-011ea8cac64c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single Decision Tree Classifier Accuracy: 0.9415\n",
            "Bagging Classifier Accuracy: 0.9591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#35. Train a Random Forest Classifier and visualize the confusion matrix"
      ],
      "metadata": {
        "id": "JqDGDuFPEPMy"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Load the dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and compute the confusion matrix\n",
        "y_pred = rf_clf.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize the confusion matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=data.target_names)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Random Forest Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "c8iMlekjERMC",
        "outputId": "638eb886-a932-417f-f666-1ba8d914d142"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#36. Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy"
      ],
      "metadata": {
        "id": "PFpsJ2ORESgb"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Load and scale the dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define base estimators\n",
        "estimators = [\n",
        "    ('dt', DecisionTreeClassifier(random_state=42)),\n",
        "    ('svc', SVC(kernel='linear', probability=True, random_state=42)), # probability=True needed for stacking\n",
        "    ('lr', LogisticRegression(solver='liblinear', random_state=42))\n",
        "]\n",
        "\n",
        "# Define the Stacking Classifier with Logistic Regression as the final estimator\n",
        "stack_clf = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=LogisticRegression(random_state=42),\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train and evaluate the Stacking Classifier\n",
        "stack_clf.fit(X_train_scaled, y_train)\n",
        "y_pred_stack = stack_clf.predict(X_test_scaled)\n",
        "acc_stack = accuracy_score(y_test, y_pred_stack)\n",
        "\n",
        "# Compare with one of the base estimators (e.g., Decision Tree)\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "dt_clf.fit(X_train_scaled, y_train)\n",
        "y_pred_dt = dt_clf.predict(X_test_scaled)\n",
        "acc_dt = accuracy_score(y_test, y_pred_dt)\n",
        "\n",
        "print(f\"Stacking Classifier Accuracy: {acc_stack:.4f}\")\n",
        "print(f\"Single Decision Tree Accuracy: {acc_dt:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbWc95_rEU7q",
        "outputId": "20632f6e-5367-4792-b81e-98e9c444dde8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 0.9883\n",
            "Single Decision Tree Accuracy: 0.9415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#37. Train a Random Forest Classifier and print the top 5 most important features"
      ],
      "metadata": {
        "id": "nm9d_5upEWDR"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "feature_names = data.feature_names\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "importances = rf_clf.feature_importances_\n",
        "\n",
        "# Combine names and scores\n",
        "feature_importances = pd.Series(importances, index=feature_names)\n",
        "\n",
        "# Sort and print top 5\n",
        "top_5_features = feature_importances.nlargest(5)\n",
        "\n",
        "print(\"Top 5 Most Important Features in Random Forest:\")\n",
        "print(top_5_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C44c8n4EEXmT",
        "outputId": "47a11440-72e9-4ce7-d1de-42857edf68de"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Most Important Features in Random Forest:\n",
            "mean concave points     0.141934\n",
            "worst concave points    0.127136\n",
            "worst area              0.118217\n",
            "mean concavity          0.080557\n",
            "worst radius            0.077975\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#38. Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score"
      ],
      "metadata": {
        "id": "ZrDbDN2GEYvV"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate a synthetic dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=0, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train the Bagging Classifier\n",
        "base_estimator = DecisionTreeClassifier(random_state=42)\n",
        "bag_clf = BaggingClassifier(\n",
        "    estimator=base_estimator,\n",
        "    n_estimators=100,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "bag_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = bag_clf.predict(X_test)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Bagging Classifier Precision: {precision:.4f}\")\n",
        "print(f\"Bagging Classifier Recall: {recall:.4f}\")\n",
        "print(f\"Bagging Classifier F1-Score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8AQhu1oEaQd",
        "outputId": "4ac14b12-b870-4e63-9299-0b2b358c0482"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Precision: 0.8919\n",
            "Bagging Classifier Recall: 0.9429\n",
            "Bagging Classifier F1-Score: 0.9167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#39. Train a Random Forest Classifier and analyze the effect of max_depth on accuracy"
      ],
      "metadata": {
        "id": "l8gZO8GJEb4X"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "max_depth_list = [3, 10, 20, None]\n",
        "results = {}\n",
        "\n",
        "print(\"Accuracy Comparison for Different max_depth values:\")\n",
        "for depth in max_depth_list:\n",
        "    rf_clf = RandomForestClassifier(n_estimators=100, max_depth=depth, random_state=42, n_jobs=-1)\n",
        "    rf_clf.fit(X_train, y_train)\n",
        "    y_pred = rf_clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results[depth] = accuracy\n",
        "    depth_str = 'None (Full)' if depth is None else str(depth)\n",
        "    print(f\"max_depth={depth_str}: Accuracy = {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V14sqDokEdpQ",
        "outputId": "fd2fde46-460a-4a58-abfc-93391cb9bc3d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Comparison for Different max_depth values:\n",
            "max_depth=3: Accuracy = 0.9708\n",
            "max_depth=10: Accuracy = 0.9708\n",
            "max_depth=20: Accuracy = 0.9708\n",
            "max_depth=None (Full): Accuracy = 0.9708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 40. Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare performance"
      ],
      "metadata": {
        "id": "GDVr8sPbEe9a"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Generate a synthetic dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 1. Bagging with Decision Tree Regressor\n",
        "dt_base = DecisionTreeRegressor(random_state=42)\n",
        "bag_dt = BaggingRegressor(estimator=dt_base, n_estimators=50, n_jobs=-1, random_state=42)\n",
        "bag_dt.fit(X_train, y_train)\n",
        "y_pred_dt = bag_dt.predict(X_test)\n",
        "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
        "\n",
        "# 2. Bagging with K-Nearest Neighbors Regressor (requires scaling)\n",
        "# Create a pipeline for KNN regressor which includes scaling\n",
        "knn_base = make_pipeline(StandardScaler(), KNeighborsRegressor(n_neighbors=5))\n",
        "bag_knn = BaggingRegressor(\n",
        "    estimator=knn_base,\n",
        "    n_estimators=50,\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    # Need to disable `check_X_features` if pipeline is used as base estimator in some older sklearn versions\n",
        ")\n",
        "bag_knn.fit(X_train, y_train)\n",
        "y_pred_knn = bag_knn.predict(X_test)\n",
        "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
        "\n",
        "print(f\"Bagging (DecisionTree Base) MSE: {mse_dt:.4f}\")\n",
        "print(f\"Bagging (KNeighbors Base) MSE: {mse_knn:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YtJll5sEgt-",
        "outputId": "8e44846d-ef56-4caa-d55d-b2fd8b551ba8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging (DecisionTree Base) MSE: 218.6192\n",
            "Bagging (KNeighbors Base) MSE: 909.8850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#41. Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score"
      ],
      "metadata": {
        "id": "ltUxmr9MEiLd"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Load the dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities (needed for ROC-AUC)\n",
        "# Use probabilities for the positive class (class 1)\n",
        "y_proba = rf_clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate ROC-AUC score\n",
        "auc_score = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "print(f\"Random Forest Classifier ROC-AUC Score: {auc_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EOXvWRNEjYZ",
        "outputId": "e81c22d0-de37-4714-c105-7935538c430c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier ROC-AUC Score: 0.9968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#42. Train a Bagging Classifier and evaluate its performance using cross-validation"
      ],
      "metadata": {
        "id": "8ZS_lh_GEkqM"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Load the dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Define the Bagging Classifier\n",
        "base_estimator = DecisionTreeClassifier(random_state=42)\n",
        "bag_clf = BaggingClassifier(\n",
        "    estimator=base_estimator,\n",
        "    n_estimators=100,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "cv_scores = cross_val_score(\n",
        "    estimator=bag_clf,\n",
        "    X=X,\n",
        "    y=y,\n",
        "    cv=5, # Number of cross-validation folds\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(f\"Cross-Validation Scores (Accuracy): {cv_scores}\")\n",
        "print(f\"Mean CV Accuracy: {cv_scores.mean():.4f}\")\n",
        "print(f\"Standard Deviation of CV Accuracy: {cv_scores.std():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJfd596XEmZa",
        "outputId": "84d078c8-ac19-4c4d-b16f-bdf190f8dfb9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores (Accuracy): [0.89473684 0.93859649 0.99122807 0.96491228 1.        ]\n",
            "Mean CV Accuracy: 0.9579\n",
            "Standard Deviation of CV Accuracy: 0.0382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#43. Train a Random Forest Classifier and plot the Precision-Recall curve"
      ],
      "metadata": {
        "id": "65mpA3s5EoOx"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay\n",
        "\n",
        "# Load the dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities for the positive class\n",
        "y_proba = rf_clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Plot the Precision-Recall curve\n",
        "display = PrecisionRecallDisplay.from_predictions(y_test, y_proba, name=\"Random Forest\")\n",
        "plt.title(\"Random Forest Precision-Recall Curve\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "L8hhy2qDEpxU",
        "outputId": "11ef85e9-be3b-404b-b09c-94d94c23244e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#44. Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy"
      ],
      "metadata": {
        "id": "PriZ3G5LErHr"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Load and scale the dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define base estimators\n",
        "estimators = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=50, random_state=42)),\n",
        "    ('lr_base', LogisticRegression(solver='liblinear', random_state=42))\n",
        "]\n",
        "\n",
        "# Define the Stacking Classifier with Logistic Regression as the final estimator\n",
        "stack_clf = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=LogisticRegression(random_state=42),\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train and evaluate the Stacking Classifier\n",
        "stack_clf.fit(X_train_scaled, y_train)\n",
        "y_pred_stack = stack_clf.predict(X_test_scaled)\n",
        "acc_stack = accuracy_score(y_test, y_pred_stack)\n",
        "\n",
        "# Compare with the Logistic Regression base estimator\n",
        "lr_clf = LogisticRegression(random_state=42)\n",
        "lr_clf.fit(X_train_scaled, y_train)\n",
        "y_pred_lr = lr_clf.predict(X_test_scaled)\n",
        "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
        "\n",
        "print(f\"Stacking Classifier Accuracy: {acc_stack:.4f}\")\n",
        "print(f\"Single Logistic Regression Accuracy: {acc_lr:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TEpHEwgEs_K",
        "outputId": "dc433de5-1637-4183-899e-62620e11e78c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 0.9766\n",
            "Single Logistic Regression Accuracy: 0.9825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#45. Train a Bagging Regressor with different levels of bootstrap samples and compare performance."
      ],
      "metadata": {
        "id": "Zpgh6iucEuwA"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Generate a synthetic dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "base_estimator = DecisionTreeRegressor(random_state=42)\n",
        "max_samples_list = [0.2, 0.5, 1.0] # Fraction of samples to draw\n",
        "results = {}\n",
        "\n",
        "print(\"MSE Comparison for Different max_samples values (Bootstrap Sample Size):\")\n",
        "for max_samples in max_samples_list:\n",
        "    bag_reg = BaggingRegressor(\n",
        "        estimator=base_estimator,\n",
        "        n_estimators=100,\n",
        "        max_samples=max_samples,\n",
        "        n_jobs=-1,\n",
        "        random_state=42\n",
        "    )\n",
        "    bag_reg.fit(X_train, y_train)\n",
        "    y_pred = bag_reg.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    results[max_samples] = mse\n",
        "    print(f\"max_samples={max_samples}: MSE = {mse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wywNAzw5Ev_B",
        "outputId": "4339da7d-bc68-476f-fb4a-489f7eee9626"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Comparison for Different max_samples values (Bootstrap Sample Size):\n",
            "max_samples=0.2: MSE = 356.6372\n",
            "max_samples=0.5: MSE = 237.3290\n",
            "max_samples=1.0: MSE = 211.5435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3yX4dBNuExbd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}